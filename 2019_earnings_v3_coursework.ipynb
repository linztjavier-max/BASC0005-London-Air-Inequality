{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/linztjavier-max/BASC0005-London-Air-Inequality/blob/main/2019_earnings_v3_coursework.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd"
      ],
      "metadata": {
        "id": "8652zJ3yxq4k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# data in earnings\n",
        "df_path_earnings = \"https://data.london.gov.uk/download/2z0rk/1686ef1c-b169-442d-8877-e7e49788f668/earnings-residence-borough.xlsx\"\n",
        "\n",
        "earnings_df = pd.read_excel(df_path_earnings, sheet_name=\"Total, weekly\")"
      ],
      "metadata": {
        "id": "vDAjUSlOlPZQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "raw_df = pd.read_excel(df_path_earnings, sheet_name=\"Total, weekly\", header=None)\n",
        "\n",
        "# Extract the first two rows to be used as header information\n",
        "header_row0 = raw_df.iloc[0] # Contains years (e.g., 2002, NaN, 2003, NaN)\n",
        "header_row1 = raw_df.iloc[1] # Contains sub-headers (e.g., Code, Area, Pay (£), conf %)\n",
        "\n",
        "# Construct new column names by combining the year and sub-header\n",
        "new_columns = []\n",
        "current_year = None\n",
        "\n",
        "for i in range(len(header_row0)):\n",
        "    year_val = header_row0.iloc[i]\n",
        "    sub_header_val = header_row1.iloc[i]\n",
        "\n",
        "    if i < 2: # Handle the first two columns ('Code', 'Area') specifically\n",
        "        new_columns.append(str(year_val).strip())\n",
        "    elif pd.isna(year_val): # If year is NaN, it's a sub-header like 'conf %' under a year\n",
        "        if current_year is not None:\n",
        "            new_columns.append(f\"{current_year} {str(sub_header_val).strip()}\")\n",
        "        else:\n",
        "            # This case implies a NaN year_val without a preceding year, which shouldn't happen for data columns\n",
        "            new_columns.append(str(sub_header_val).strip()) # Fallback for safety\n",
        "    else: # Year value is present (e.g., 2002, 2003, ...)\n",
        "        current_year = int(year_val)\n",
        "        new_columns.append(f\"{current_year} {str(sub_header_val).strip()}\")\n",
        "\n",
        "# Create the earnings_clean DataFrame by taking data from the third row onwards\n",
        "# and assigning the newly constructed column names.\n",
        "earnings_clean = raw_df.iloc[2:].copy()\n",
        "earnings_clean.columns = new_columns\n",
        "earnings_clean = earnings_clean.reset_index(drop=True)\n",
        "\n",
        "# Remove all 'conf %' columns\n",
        "columns_to_drop = [col for col in earnings_clean.columns if 'conf %' in col]\n",
        "earnings_clean = earnings_clean.drop(columns=columns_to_drop)\n",
        "\n",
        "# Identify the columns for 'Pay (£)' for years 2011 to 2024\n",
        "years_to_keep = list(range(2019, 2023))\n",
        "pay_columns = [f\"{year} Pay (£)\" for year in years_to_keep]\n",
        "\n",
        "# Ensure 'Code' and 'Area' are always kept\n",
        "final_columns = ['Code', 'Area'] + pay_columns\n",
        "\n",
        "# Filter earnings_clean to retain only these selected columns\n",
        "earnings_clean = earnings_clean[final_columns]\n",
        "\n",
        "earnings_clean_df = earnings_clean.iloc[0:34]\n",
        "\n",
        "print(\"Cleaned earnings_clean DataFrame:\")\n",
        "earnings_clean_df"
      ],
      "metadata": {
        "collapsed": true,
        "id": "k_RF0jPhlVSN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "earnings_df_2019=earnings_clean_df[[\"Code\", \"Area\", \"2019 Pay (£)\"]]\n",
        "earnings_df_2019"
      ],
      "metadata": {
        "collapsed": true,
        "id": "kEZpQA1RlZFR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#choropleth 2019 income\n",
        "#import necessary libraries\n",
        "\n",
        "import warnings\n",
        "\n",
        "import geopandas as gpd\n",
        "import libpysal as lps\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import esda"
      ],
      "metadata": {
        "id": "J3Kq3UZqeJBO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "geojson_url = \"https://hub.arcgis.com/api/v3/datasets/0a92a355a8094e0eb20a7a66cf4ca7cf_10/downloads/data?format=geojson&spatialRefId=4326&where=1%3D1\"\n",
        "output_filename = \"london_boroughs.geojson\""
      ],
      "metadata": {
        "id": "LGQ4LwZBw5Tn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "\n",
        "# Download the GeoJSON file\n",
        "response = requests.get(geojson_url)\n",
        "response.raise_for_status()  # Raise an exception for bad status codes\n",
        "\n",
        "with open(output_filename, 'wb') as f:\n",
        "    f.write(response.content)\n",
        "\n",
        "gdf = gpd.read_file(output_filename)"
      ],
      "metadata": {
        "collapsed": true,
        "id": "4fwsPyWseLsa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gdf"
      ],
      "metadata": {
        "collapsed": true,
        "id": "AJMNUtRtYKbO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.random.seed(12345)\n",
        "import esda"
      ],
      "metadata": {
        "id": "5Zeeb_P33_5o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "earnings_df_2019_borough = earnings_df_2019.rename(columns={'Area': 'Borough'})"
      ],
      "metadata": {
        "id": "8rIQ2Vx4YXTC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "earnings_df_2019_borough = earnings_df_2019_borough.rename(columns={'Code': 'LA_Code'})"
      ],
      "metadata": {
        "id": "KhJa_M5waOhx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Standardise borough names: inspect the unique values in the 'Borough' column\n",
        "earnings_df_2019_borough['Borough'].unique()"
      ],
      "metadata": {
        "collapsed": true,
        "id": "RNUD7-WH4mWM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Inspect the unique values in the 'BOROUGH' column of the gdf DataFrame to compare them with the unique borough names from vehicles_df_2019_borough and identify any inconsistencies.\n",
        "gdf['BOROUGH'].unique()"
      ],
      "metadata": {
        "collapsed": true,
        "id": "C4w4qAt64o4M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#edit names where necessary in vehicles df to match gdf\n",
        "earnings_df_2019_borough['Borough'] = earnings_df_2019_borough['Borough'].replace({\n",
        "    'Barking and Dagenham': 'Barking & Dagenham',\n",
        "    'Hammersmith and Fulham': 'Hammersmith & Fulham',\n",
        "    'Kensington and Chelsea': 'Kensington & Chelsea'\n",
        "})\n",
        "\n",
        "print(\"Unique borough names in earnings_df_2019_borough after standardization:\")\n",
        "print(earnings_df_2019_borough['Borough'].unique())"
      ],
      "metadata": {
        "collapsed": true,
        "id": "xnSNNAdj42Uz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Confirm all naming inconsistencies have been resolved\n",
        "diff_earnings_not_in_gdf = set(earnings_df_2019_borough['Borough'].unique()) - set(gdf['BOROUGH'].unique())\n",
        "diff_gdf_not_in_earnings = set(gdf['BOROUGH'].unique()) - set(earnings_df_2019_borough['Borough'].unique())\n",
        "\n",
        "print(\"Borough names in earnings_df_2019_boroughh but not in gdf:\", diff_earnings_not_in_gdf)\n",
        "print(\"Borough names in gdf but not in earnings_df_2019_borough:\", diff_gdf_not_in_earnings)"
      ],
      "metadata": {
        "collapsed": true,
        "id": "HFgovEf647O-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#remove nan from earnings df\n",
        "earnings_df_2019_borough = earnings_df_2019_borough.dropna(subset=['Borough'])\n",
        "\n",
        "regions_to_remove = [\n",
        "    'nan'\n",
        "]\n",
        "\n",
        "earnings_df_2019_borough = earnings_df_2019_borough[~earnings_df_2019_borough['Borough'].isin(regions_to_remove)]\n",
        "\n",
        "print(\"Unique borough names in earnings_df_2019_borough after removal:\")\n",
        "print(earnings_df_2019_borough['Borough'].unique())"
      ],
      "metadata": {
        "collapsed": true,
        "id": "helqM98rnYmj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#merge the data frames by using left merge (borough names as keys), then remove extra borough column\n",
        "gdf_merged_2019 = gdf.merge(earnings_df_2019_borough, left_on='BOROUGH', right_on='Borough', how='left')\n",
        "gdf_merged_2019 = earnings_df_2019_borough.drop(columns=['Borough'])\n",
        "gdf_merged_2019.head()"
      ],
      "metadata": {
        "collapsed": true,
        "id": "1Oc56xm75Cn_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Check for missing values in merged '2019 Pay (£)' column of the gdf_merged_2019 DataFrame using the .isnull().sum() method.\n",
        "gdf_merged_2019['2019 Pay (£)'].isnull().sum()"
      ],
      "metadata": {
        "collapsed": true,
        "id": "19ByYIqx5JOQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# The error occurs because gdf_merged_2019 is a pandas DataFrame, not a GeoDataFrame,\n",
        "# which is required by gpd.sjoin for spatial predicates like \"intersects\".\n",
        "# The previous cell incorrectly overwrote the GeoDataFrame resulting from the merge\n",
        "# with a plain DataFrame.\n",
        "\n",
        "# To fix this, we should perform a non-spatial merge between the gdf (GeoDataFrame)\n",
        "# and the earnings data (earnings_df_2019_borough DataFrame) to combine the attributes\n",
        "# based on borough names. This will create a new GeoDataFrame with the earnings data.\n",
        "sj_gdf = gdf.merge(\n",
        "    earnings_df_2019_borough,\n",
        "    left_on='BOROUGH',\n",
        "    right_on='Borough',\n",
        "    how='left'\n",
        ")\n",
        "\n",
        "# Convert the '2019 Pay (£)' column to numeric, coercing errors to NaN\n",
        "sj_gdf['2019 Pay (£)'] = pd.to_numeric(sj_gdf['2019 Pay (£)'], errors='coerce')\n",
        "\n",
        "# Drop the redundant 'Borough' and 'LA_Code' columns from the merged GeoDataFrame\n",
        "sj_gdf = sj_gdf.drop(columns=['Borough', 'LA_Code'])\n",
        "\n",
        "sj_gdf.head()"
      ],
      "metadata": {
        "id": "YB1-f04o5fF9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Calculate mean earnings for each borough using the 2019 Pay (£) column and group the results by BOROUGH from the sj_gdf GeoDataFrame, storing the result in mean_earnings_gb\n",
        "mean_earnings_gb = sj_gdf.groupby('BOROUGH')['2019 Pay (£)'].mean()\n",
        "mean_earnings_gb.name = '2019 Earnings mean'\n",
        "mean_earnings_gb"
      ],
      "metadata": {
        "collapsed": true,
        "id": "iZzAXEzC5kfc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Merge calculated mean earnings for each borough (mean_earnings_gb) back into the gdf GeoDataFrame. This will associate the earnings data with the geographical features, which is essential for spatial analysis and visualization.\n",
        "gdf = gdf.merge(mean_earnings_gb, left_on='BOROUGH', right_on='BOROUGH', how='left')\n",
        "gdf.head()"
      ],
      "metadata": {
        "collapsed": true,
        "id": "Km2m3WRv5npq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Create choropleth map using gdf DataFrame, specifying plot size, column mapping, color scheme, legend, axis removal, and title\n",
        "import matplotlib.pyplot as plt\n",
        "import mapclassify as mc\n",
        "\n",
        "fig, ax = plt.subplots(1, figsize=(12, 10), subplot_kw={'aspect': 'equal'})\n",
        "gdf.plot(column='2019 Earnings mean',scheme='Quantiles', k=5, cmap='OrRd', legend=True, ax=ax)\n",
        "ax.set_axis_off()\n",
        "plt.title('2019 Earnings Across London Boroughs')\n",
        "plt.show()"
      ],
      "metadata": {
        "collapsed": true,
        "id": "5auUnz-mcftp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Create choropleth map using gdf DataFrame, specifying plot size, column mapping, color scheme, legend, axis removal, and title\n",
        "import matplotlib.pyplot as plt\n",
        "import mapclassify as mc\n",
        "\n",
        "fig, ax = plt.subplots(1, figsize=(12, 10), subplot_kw={'aspect': 'equal'})\n",
        "gdf.plot(column='2019 Earnings mean', cmap='OrRd', legend=True, ax=ax)\n",
        "ax.set_axis_off()\n",
        "plt.title('2019 Earnings Across London Boroughs')\n",
        "plt.show()"
      ],
      "metadata": {
        "collapsed": true,
        "id": "c4Gt4BvY5xym"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_PTG9TCg6Azv"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}